#include <vector>
#include <cmath>
#include "VectorMaths.h"

namespace nlp::embedding_utils {

    std::vector<float> VectorMaths::mean_pooling(
        const std::vector<std::vector<float>>& token_embeddings,
        const std::vector<tokenizer::Token>& original_tokens
    ) {
        if (token_embeddings.empty()) return {};

        size_t hidden_size = token_embeddings[0].size();
        std::vector<float> sentence_embedding(hidden_size, 0.0f);
        int valid_token_count = 0;

        for (size_t i = 0; i < token_embeddings.size(); ++i) {
            // ONLY process tokens where attention_mask is 1 (ignores [PAD])
            if (original_tokens[i].attention_mask == 1) {
                valid_token_count++;
                for (size_t d = 0; d < hidden_size; ++d) {
                    sentence_embedding[d] += token_embeddings[i][d];
                }
            }
        }

        if (valid_token_count > 0) {
            for (float& val : sentence_embedding) {
                val /= static_cast<float>(valid_token_count);
            }
        }

        return sentence_embedding;
    }

    float VectorMaths::cosine_similarity(
        const std::vector<float>& vec_a,
        const std::vector<float>& vec_b
    ) {
        float dot = 0.0f, norm_a = 0.0f, norm_b = 0.0f;
        for (size_t i = 0; i < vec_a.size(); ++i) {
            dot += vec_a[i] * vec_b[i];
            norm_a += vec_a[i] * vec_a[i];
            norm_b += vec_b[i] * vec_b[i];
        }
        return (norm_a == 0 || norm_b == 0) ? 0.0f : dot / (std::sqrt(norm_a) * std::sqrt(norm_b));
    }

} // namespace nlp::embedding_utils
